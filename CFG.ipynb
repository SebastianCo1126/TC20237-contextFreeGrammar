{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "# nltk.download('punkt')\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> E\n",
        "    E -> P F\n",
        "    F -> '+' E |'-' E | '.'\n",
        "    P -> INT T DIFF\n",
        "    T -> VAR EXP | CONST R | CONST | '.'\n",
        "    R -> VAR EXP | CONST T | '.'\n",
        "    INT -> '%'\n",
        "    DIFF -> 'dx'\n",
        "    VAR -> 'x'\n",
        "    CONST -> '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'\n",
        "    EXP -> '^' CONST | '.'\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "jQuqm8hMGMb0"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valid tests section"
      ],
      "metadata": {
        "id": "G2Z2OHW8VDS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 1"
      ],
      "metadata": {
        "id": "XEYOoT6tYghm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence = \"% 2 x ^ 2 dx .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-r3l3nXVCO0",
        "outputId": "ca853bc6-21ca-4380-805c-fb186845ca0f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   S                    \n",
            "                   |                     \n",
            "                   E                    \n",
            "            _______|__________________   \n",
            "           P                          | \n",
            "  _________|_____________________     |  \n",
            " |             T                 |    | \n",
            " |     ________|___              |    |  \n",
            " |    |            R             |    | \n",
            " |    |     _______|___          |    |  \n",
            " |    |    |          EXP        |    | \n",
            " |    |    |        ___|____     |    |  \n",
            "INT CONST VAR      |      CONST DIFF  F \n",
            " |    |    |       |        |    |    |  \n",
            " %    2    x       ^        2    dx   . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 2"
      ],
      "metadata": {
        "id": "9taGwStCYk33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence2 = \"% 2 x ^ 2 dx + % 7 dx .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence2)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQraAvE0YmOl",
        "outputId": "a87cef83-1d17-4f38-8277-7d535b2e026b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 S                             \n",
            "                                 |                              \n",
            "                                 E                             \n",
            "            _____________________|_____________                 \n",
            "           P                                   F               \n",
            "  _________|_____________________      ________|____            \n",
            " |             T                 |    |             E          \n",
            " |     ________|___              |    |         ____|________   \n",
            " |    |            R             |    |        P             | \n",
            " |    |     _______|___          |    |    ____|________     |  \n",
            " |    |    |          EXP        |    |   |    T        |    | \n",
            " |    |    |        ___|____     |    |   |    |        |    |  \n",
            "INT CONST VAR      |      CONST DIFF  |  INT CONST     DIFF  F \n",
            " |    |    |       |        |    |    |   |    |        |    |  \n",
            " %    2    x       ^        2    dx   +   %    7        dx   . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 3"
      ],
      "metadata": {
        "id": "mSknEbafYsgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence3 = \"% 2 x ^ 2 dx + % 5 x ^ 3 dx .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence3)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4iYKBJ8Y6kL",
        "outputId": "7eda0108-352c-47ce-94b0-6b2a7316253c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      S                                          \n",
            "                                      |                                           \n",
            "                                      E                                          \n",
            "            __________________________|_____________                              \n",
            "           |                                        F                            \n",
            "           |                           _____________|_______                      \n",
            "           |                          |                     E                    \n",
            "           |                          |              _______|__________________   \n",
            "           P                          |             P                          | \n",
            "  _________|_____________________     |    _________|_____________________     |  \n",
            " |             T                 |    |   |             T                 |    | \n",
            " |     ________|___              |    |   |     ________|___              |    |  \n",
            " |    |            R             |    |   |    |            R             |    | \n",
            " |    |     _______|___          |    |   |    |     _______|___          |    |  \n",
            " |    |    |          EXP        |    |   |    |    |          EXP        |    | \n",
            " |    |    |        ___|____     |    |   |    |    |        ___|____     |    |  \n",
            "INT CONST VAR      |      CONST DIFF  |  INT CONST VAR      |      CONST DIFF  F \n",
            " |    |    |       |        |    |    |   |    |    |       |        |    |    |  \n",
            " %    2    x       ^        2    dx   +   %    5    x       ^        3    dx   . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 4\n"
      ],
      "metadata": {
        "id": "YUxTKu2XZLKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence4 = \"% 8 1 x ^ 8 dx - % 7 2 1 x ^ 2 dx + % 5 dx .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence4)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie5ICduIZJ7m",
        "outputId": "e1e12274-6f18-44d1-cb12-4af7413bd16f"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                           S                                                              \n",
            "                                                           |                                                               \n",
            "                                                           E                                                              \n",
            "                  _________________________________________|__________________                                             \n",
            "                 |                                                            F                                           \n",
            "                 |                           _________________________________|________                                    \n",
            "                 |                          |                                          E                                  \n",
            "                 |                          |                     _____________________|__________________                 \n",
            "                 |                          |                    P                                        |               \n",
            "                 |                          |    ________________|__________________________              |                \n",
            "                 P                          |   |                T                          |             |               \n",
            "  _______________|_____________________     |   |     ___________|____                      |             |                \n",
            " |               T                     |    |   |    |                R                     |             F               \n",
            " |     __________|___                  |    |   |    |      __________|___                  |     ________|____            \n",
            " |    |              R                 |    |   |    |     |              T                 |    |             E          \n",
            " |    |      ________|___              |    |   |    |     |      ________|___              |    |         ____|________   \n",
            " |    |     |            T             |    |   |    |     |     |            R             |    |        P             | \n",
            " |    |     |     _______|___          |    |   |    |     |     |     _______|___          |    |    ____|________     |  \n",
            " |    |     |    |          EXP        |    |   |    |     |     |    |          EXP        |    |   |    T        |    | \n",
            " |    |     |    |        ___|____     |    |   |    |     |     |    |        ___|____     |    |   |    |        |    |  \n",
            "INT CONST CONST VAR      |      CONST DIFF  |  INT CONST CONST CONST VAR      |      CONST DIFF  |  INT CONST     DIFF  F \n",
            " |    |     |    |       |        |    |    |   |    |     |     |    |       |        |    |    |   |    |        |    |  \n",
            " %    8     1    x       ^        8    dx   -   %    7     2     1    x       ^        2    dx   +   %    5        dx   . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 5"
      ],
      "metadata": {
        "id": "jPHZ245Kawgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence5 = \"% 1 0 2 1 x . dx - % 1 2 x . dx + % 1 3 x ^ 9 dx - % 1 dx .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence5)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdjMWSRta2eH",
        "outputId": "5704dfc4-dbfa-40b2-987e-192f9676bf8e"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             S                                                                                                                     \n",
            "                                             |                                                                                                                      \n",
            "                                             E                                                                                                                     \n",
            "                   __________________________|___________________                                                                                                   \n",
            "                  |                                              F                                                                                                 \n",
            "                  |                                ______________|____________________                                                                              \n",
            "                  |                               |                                   E                                                                            \n",
            "                  |                               |               ____________________|___________________                                                          \n",
            "                  |                               |              |                                        F                                                        \n",
            "                  |                               |              |                          ______________|_____________________                                    \n",
            "                  P                               |              |                         |                                    E                                  \n",
            "  ________________|__________________________     |              |                         |                    ________________|__________________                 \n",
            " |                T                          |    |              |                         |                   P                                   |               \n",
            " |     ___________|_____                     |    |              |                         |    _______________|_____________________              |                \n",
            " |    |                 R                    |    |              P                         |   |               T                     |             F               \n",
            " |    |      ___________|____                |    |    __________|____________________     |   |     __________|___                  |     ________|____            \n",
            " |    |     |                T               |    |   |               T               |    |   |    |              R                 |    |             E          \n",
            " |    |     |      __________|___            |    |   |     __________|___            |    |   |    |      ________|___              |    |         ____|________   \n",
            " |    |     |     |              R           |    |   |    |              R           |    |   |    |     |            T             |    |        P             | \n",
            " |    |     |     |      ________|___        |    |   |    |      ________|___        |    |   |    |     |     _______|___          |    |    ____|________     |  \n",
            " |    |     |     |     |            T       |    |   |    |     |            T       |    |   |    |     |    |          EXP        |    |   |    T        |    | \n",
            " |    |     |     |     |         ___|___    |    |   |    |     |         ___|___    |    |   |    |     |    |        ___|____     |    |   |    |        |    |  \n",
            "INT CONST CONST CONST CONST     VAR     EXP DIFF  |  INT CONST CONST     VAR     EXP DIFF  |  INT CONST CONST VAR      |      CONST DIFF  |  INT CONST     DIFF  F \n",
            " |    |     |     |     |        |       |   |    |   |    |     |        |       |   |    |   |    |     |    |       |        |    |    |   |    |        |    |  \n",
            " %    1     0     2     1        x       .   dx   -   %    1     2        x       .   dx   +   %    1     3    x       ^        9    dx   -   %    1        dx   . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Invalid tests"
      ],
      "metadata": {
        "id": "32i3JTdEedcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invalid test 1"
      ],
      "metadata": {
        "id": "vGeWzyjqefBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence6 = \"% 1 3 x ^ 2 .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence6)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "id": "jEWhV6lPehVf"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an invalid test, so it doesn't print anything."
      ],
      "metadata": {
        "id": "ote2DSyagEg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invalid test 2"
      ],
      "metadata": {
        "id": "wGhNxFc1gLRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence7 = \"% 7 x ^ 2 dx + % 1 7 y dx .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence7)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "k1CsSIBKgJmH",
        "outputId": "2ee8552b-6914-4cd7-f778-cdb949d27873"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Grammar does not cover some of the input words: \"'y'\".",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-6efbe3ff606d>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Parse the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mchart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chart_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mcheck_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{w!r}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0;34m\"Grammar does not cover some of the \"\u001b[0m \u001b[0;34m\"input words: %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'y'\"."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this test case an error is return as y has not been defined in the grammar."
      ],
      "metadata": {
        "id": "qccPXywrguvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invalid test 3"
      ],
      "metadata": {
        "id": "QB6gBaXNg1QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence8 = \"% 4 5 1 x ^ 1 0 dx .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence8)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "id": "H74wvqwDg5T7"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an invalid test, so it doesn't print anything."
      ],
      "metadata": {
        "id": "p7YJHTL2hgQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invalid test 4"
      ],
      "metadata": {
        "id": "EiFl4yuJhijo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence9 = \"% 1 0 dx + % 9 x ^ 4 - 1 0 dx .\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence9)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "id": "5G9V3_uMhh3r"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an invalid test, so it doesn't print anything."
      ],
      "metadata": {
        "id": "QVD6yl2ojidc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invalid test 5"
      ],
      "metadata": {
        "id": "1VnxlgQPkWWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a parser with the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Input sentence to be parsed\n",
        "sentence9 = \"% 9 8 x ^ 5 dx - % 1 x ^ 2 + % 1 0 0 dx + % 12 x dx\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence9)\n",
        "\n",
        "# Parse the sentence\n",
        "for tree in parser.parse(tokens):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "dN-smFWJkZUA",
        "outputId": "0668ce25-e52c-411e-b15a-01d45eb56527"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Grammar does not cover some of the input words: \"'12'\".",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-d1bc14cc0391>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Parse the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mchart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chart_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mcheck_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{w!r}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0;34m\"Grammar does not cover some of the \"\u001b[0m \u001b[0;34m\"input words: %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'12'\"."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is returns an error, because the number 12 isn't separated by a space."
      ],
      "metadata": {
        "id": "zYz4ricGklD8"
      }
    }
  ]
}